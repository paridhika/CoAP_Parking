{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/CoAP_Parking/blob/master/CSC2515_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8loDujPQPhrq"
      },
      "source": [
        "# Active Transfer Learning\n",
        "\n",
        "In this project we experiment different active learning setups. To run the code with "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfJnQ9-7yl8O"
      },
      "source": [
        "## Importing and setting GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0-Xc4Y1mq0U",
        "outputId": "4a2435b4-5bd3-4990-bcfe-0ba1ad634e45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "!pip install transformers\n",
        "!pip install scikeras[tensorflow]\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib inline\n",
        "import json\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "!pip install modAL\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "def save_result(h,dest_add):\n",
        "  with open(dest_add, 'wb') as f:\n",
        "    np.save(f, h)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.9/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras[tensorflow]) (1.2.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras[tensorflow]) (23.1)\n",
            "Requirement already satisfied: tensorflow>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from scikeras[tensorflow]) (2.12.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.22.4)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.53.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (4.5.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (67.6.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (16.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.32.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (23.3.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.11.0->scikeras[tensorflow]) (0.1.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (6.4.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: modAL in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.9/dist-packages (from modAL) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from modAL) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.9/dist-packages (from modAL) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.9/dist-packages (from modAL) (1.10.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->modAL) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->modAL) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->modAL) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->modAL) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7xhV_DPAz5",
        "outputId": "df9a3fcd-b09d-4bfe-de98-a701b5cce380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMhaZEKEPIJ2",
        "outputId": "d6bf9851-6448-485d-c276-58dacd6ea8f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "WkSkme4-1QMe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKg1VPGPgL6"
      },
      "source": [
        "## Loading and preprocessing data :\n",
        "We can either use the preprocess data fetched from my Github repo or them in the last section then running these cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8dAuAY1aTk6",
        "outputId": "d8c04253-7c51-4007-9ac3-418f12c5a88a"
      },
      "source": [
        "!git clone \"https://github.com/parsafarinnia/sentiment_new_approach\"\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sentiment_new_approach' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOcePxwdUjcd"
      },
      "source": [
        "topic_num=0\n",
        "\n",
        "all_topics = pickle.load(open(\"/content/sentiment_new_approach/all_topics_with_meta.p\",\"rb\"))\n",
        "data=pd.DataFrame.from_dict(all_topics[0]).T\n",
        "data['topic']=0\n",
        "tags = data.tag.values\n",
        "\n",
        "for i in range(1,9):\n",
        "  topic = pd.DataFrame.from_dict(all_topics[i]).T\n",
        "  topic['topic'] = i\n",
        "  data = pd.concat([data,topic],axis=0)\n",
        "\n",
        "\n",
        "#Converting boolean features into integers in the dataset\n",
        "map={\"rumours\":1,\"non-rumours\":0}\n",
        "data=data.replace({'tag':map})\n",
        "map={\"photo\":1,\"none\":0}\n",
        "data=data.replace({'media_type':map})\n",
        "map={True:1,False:0}\n",
        "data=data.replace({'verified':map})\n",
        "\n",
        "\n",
        "#Normalizing features\n",
        "import copy\n",
        "df=copy.deepcopy(data)\n",
        "cols=['favorite_count_log','retweet_count','followers','follow_ratio','length','capital_ratio']\n",
        "for item in cols:\n",
        "  column=item\n",
        "  df[column] = (df[column]-df[column].min()) /(df[column].max()-df[column].min())\n",
        "\n",
        "\n",
        "data=df\n",
        "train_df = data[data['topic']!=topic_num]\n",
        "train_sentences=train_df.text.values\n",
        "train_labels=train_df.tag.values\n",
        "\n",
        "test_df = data[data['topic']==topic_num]\n",
        "test_sentences=test_df.text.values\n",
        "test_labels=test_df.tag.values\n",
        "\n",
        "\n",
        "data2=data.reset_index()\n",
        "def pd_iter_func(df,topic):\n",
        "    for row in df.itertuples():\n",
        "        # Define your criteria here\n",
        "        if row.topic==topic:\n",
        "            return row\n",
        "\n",
        "start_test=pd_iter_func(data2,topic_num).Index\n",
        "\n",
        "if topic_num==8: \n",
        "  end_test=len(data2)\n",
        "else:\n",
        "  end_test=pd_iter_func(data2,topic_num+1).Index-1\n",
        "\n",
        "train_start=start_test\n",
        "train_end=end_test"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Active learning multiple runs\n",
        "since every model might have a different input out put and training specific setting we have multiple functions for different model. The Multi part comes from the fact that we need to run the model multiple time to avoid the randomness effect of selecting a specific train test. we do this because our data set is around 2k and we want conrecete results\n"
      ],
      "metadata": {
        "id": "uY0RdW2xskeX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4DI_eYiqIY"
      },
      "source": [
        "###Run_multy_episolon_greedy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "jTs4l8HGIX4h"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiW-lOdUiy_j"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def run_multy_epsilon_greedy(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_confusion = np.zeros((num_of_run,N_QUERIES+1,4))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "\n",
        "    clf = get_model(model_name)\n",
        "    \n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "    #Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling).\n",
        "    counter_random= 1 \n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "    pref_confusion[i][0] = [tn, fp, fn, tp]\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      counter_random += 1 \n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      if not is_random:\n",
        "        query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      index_list = range(len(X_pool))\n",
        "      query_index = random.sample(index_list,10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "    \n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting.\n",
        "      tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "      pref_confusion[i][index] = [tn, fp, fn, tp]\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      #Calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r1Z3f4X-lsu"
      },
      "source": [
        "### Run_multy_sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6thIy2-n-qLt"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from keras import utils as np_utils\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy_sklearn(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_confusion = np.zeros((num_of_run,N_QUERIES+1,4))\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "    pref_confusion[i][0] = [tn, fp, fn, tp]\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random : #or counter_random % random_ratio == 0:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "\n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting\n",
        "      tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "      pref_confusion[i][index] = [tn, fp, fn, tp]\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      #Calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GAW2YLTWb73"
      },
      "source": [
        "### run_multy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJzQWwYOTHVc"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from keras import utils as np_utils\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy(BATCH_SIZE,data_test,test_labels,num_of_run,model,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test,test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  print(num_of_run,N_QUERIES)\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "\n",
        "  test_labels = keras.utils.np_utils.to_categorical(test_labels, 2)  \n",
        "  \n",
        "  for i in range(num_of_run):\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    clf = KerasClassifier(build_fn=model, epochs=50, batch_size=35, verbose=0)\n",
        "\n",
        "    print('x pool length',X_train.shape)\n",
        "    print('y pool length',y_train.shape)\n",
        "    print(\"Paridhika\")\n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "    print('8888888888888888888888888888888888888888')\n",
        "    print(y_pool[0],y_pool[1],y_pool[2])\n",
        "    print('shapeè',y_pool.shape)\n",
        "  \n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    y_test_cat = np.argmax(y_test,axis=1)\n",
        "    macro=f1_score(y_test_cat,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    y_train_cat = np.argmax(y_test,axis=1)\n",
        "    counts = np.bincount(y_train_cat)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test_cat))]\n",
        "    macro=f1_score( y_test_cat,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "\n",
        "      print('x pool length',len(X_pool))\n",
        "      print('y pool length',len(y_pool))\n",
        "      print(i,'th run and query number',index)\n",
        "      \n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "    \n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      for j in range(5):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(data_test, test_labels)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      #y_pred_cat=np.argmax(y_pred)\n",
        "      y_test_cat=np.argmax(y_test,axis=1)\n",
        "      print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score( y_test_cat,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "      # performance_history_acc.append(model_accuracy)\n",
        "      # performance_history_f1.append(macro)\n",
        "      # perf_hist_multy[i][0].append(model_accuracy)\n",
        "      # perf_hist_multy[i][1].append(macro)\n",
        "\n",
        "      #Calculate and add majority\n",
        "      y_train_cat = np.argmax(y_test,axis=1)\n",
        "      counts = np.bincount(y_train_cat)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test_cat))]\n",
        "      macro=f1_score(y_test_cat,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      \n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES\n",
        "    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4Jr0aWQN85"
      },
      "source": [
        "### Run_multy (for pytorch MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeJI2HwTR0t_"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy(BATCH_SIZE,data_test,test_labels,num_of_run,model,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test,test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "  print(num_of_run,N_QUERIES)\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "\n",
        "  test_labels = keras.utils.to_categorical(test_labels, 2)  \n",
        "  for i in range(num_of_run):\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    clf = KerasClassifier(model=model)\n",
        "    print('x pool length',X_train.shape)\n",
        "    print('y pool length',y_train.shape)\n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    # Allow our model to query our unlabeled dataset for the most\n",
        "    # informative points according to our query strategy (uncertainty sampling).\n",
        "    \n",
        "    # calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    y_test_cat = np.argmax(y_test,axis=1)\n",
        "    macro=f1_score(y_test_cat,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    # calculate initial batch majority\n",
        "    y_train_cat = np.argmax(y_test,axis=1)\n",
        "    counts = np.bincount(y_train_cat)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "    #calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test_cat))]\n",
        "    macro=f1_score( y_test_cat,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    \n",
        "\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      # print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "      # Teach our ActiveLearner model the record it has requested.\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(5):\n",
        "        learner.teach(X=X, y=y)\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(data_test, test_labels)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      # y_pred_cat=np.argmax(y_pred)\n",
        "      y_test_cat=np.argmax(y_test,axis=1)\n",
        "      # print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score( y_test_cat,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "       # calculate and add majority\n",
        "      y_train_cat = np.argmax(y_test,axis=1)\n",
        "      counts = np.bincount(y_train_cat)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test_cat))]\n",
        "      macro=f1_score(y_test_cat,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      \n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "  return pref_hist_multy_acc_avg,pref_hist_multy_f1_avg ,pref_random,pref_hist_majority_avg#,pref_hist_multy_accuracy,pref_hist_multy_f1\n",
        "    "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOYSeV_xX7nt"
      },
      "source": [
        "### run_multy_committe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BksKfnVnX4qn"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "from modAL.models import ActiveLearner, Committee\n",
        "\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "commite_size = 5\n",
        "\n",
        "def run_multy_commite(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random,mode):\n",
        " \n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "\n",
        "  pref_random = 0\n",
        "  boost = False\n",
        "  if mode=='boost'or mode=='bag':\n",
        "    boost= True\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    learner_list = []\n",
        "    for j in range(commite_size):\n",
        "      learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train,bootstrap_init=boost,)\n",
        "      learner_list.append(learner)\n",
        "\n",
        "    committee = Committee(learner_list=learner_list)\n",
        "    if mode=='bag':\n",
        "      committee.rebag()\n",
        "    t1 = time.time()\n",
        "\n",
        "    # calculate initial batch\n",
        "    y_pred = committee.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #active leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      t2 = time.time()\n",
        "\n",
        "      query_index, query_instance = committee.query(X_pool)\n",
        "\n",
        "      if is_random : #or counter_random % random_ratio == 0:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "    \n",
        "      for j in range(1):\n",
        "        committee.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = committee.score(X_test, y_test)\n",
        "      y_pred = committee.predict(X_test)\n",
        "\n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuaLfSdd36WP"
      },
      "source": [
        "### Run_multy_cross"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddCV-3MT3_BL"
      },
      "source": [
        "def run_multy_cross(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "\n",
        "    #Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling)\n",
        "    counter_random= 1 \n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      counter_random += 1 \n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      index_list = range(len(X_pool))\n",
        "      query_index = random.sample(index_list,10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      X_train = np.concatenate((X_train, X))\n",
        "      y_train = np.concatenate((y_train, y))\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "        \n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "    print(format_time(time.time()-t1))\n",
        "\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3jwCE8sQ3Q"
      },
      "source": [
        "###Run_multy for mlp that uses Keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, GlobalMaxPooling1D, Activation\n",
        "from keras.layers import Embedding, LSTM\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "def create_keras_model_berts():\n",
        "  model = Sequential()\n",
        "  model.add(keras.Input(shape=(768,),name=\"source\"))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.3))\n",
        "  # model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def create_keras_model_GLOVE():\n",
        "  model = Sequential()\n",
        "  model.add(keras.Input(shape=(200,),name=\"source\"))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.3))\n",
        "  # model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VepX1HYwd5Ye"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get model\n",
        "getting all generated models that were tested"
      ],
      "metadata": {
        "id": "OuHBSHj33O3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "def get_model(model_name):\n",
        "  if model_name == \"bag\":\n",
        "    clf = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100, max_samples=0.8)\n",
        "  if model_name == \"xgb\":\n",
        "    clf = XGBClassifier()\n",
        "  if model_name == \"gbc\":\n",
        "    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1, max_depth=1)\n",
        "  if model_name ==\"Ada\":\n",
        "    clf = AdaBoostClassifier(n_estimators=200,learning_rate=0.01)\n",
        "  if model_name ==\"svm\":\n",
        "    clf=svm.SVC(probability=True)\n",
        "  if model_name ==\"rf\":\n",
        "    clf=RandomForestClassifier(max_depth=1000, random_state=0)\n",
        "  if model_name ==\"LR\":\n",
        "    clf=LogisticRegression(random_state=0,class_weight='balanced')\n",
        "  if model_name ==\"knn3\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=3)\n",
        "  if model_name ==\"knn5\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=5)\n",
        "  if model_name ==\"gp\":\n",
        "     clf=GaussianProcessClassifier()\n",
        "  if model_name ==\"lda\":\n",
        "    clf=LinearDiscriminantAnalysis()\n",
        "  if model_name ==\"qda\":\n",
        "    clf=QuadraticDiscriminantAnalysis() \n",
        "  return clf"
      ],
      "metadata": {
        "id": "TuYbVoY3_aSC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimension Reduction"
      ],
      "metadata": {
        "id": "6jBdLtbNtueU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence features with PCA\n",
        "Dimension reduction using PCA for all features"
      ],
      "metadata": {
        "id": "8D7yERbQ3WOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "pca=PCA(0.75)\n",
        "sentence_feature_normal=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/normal_bert.npy'))\n",
        "sentence_feature_tweet =pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/tweet_bert.npy'))\n",
        "sentence_feature_GLOVE =pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE.np'))\n",
        "sentence_feature_GLOVE25=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE25.np'))\n",
        "sentence_feature_GLOVE50=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE50.np'))\n",
        "sentence_feature_GLOVE100=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE100.np'))\n"
      ],
      "metadata": {
        "id": "tJCDwTJD1Mpy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence features with PCA concatenated with metadata"
      ],
      "metadata": {
        "id": "326zohgZ-Pd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s0=data[cols]\n",
        "s1=pd.DataFrame(sentence_feature_normal)\n",
        "s2=pd.DataFrame(sentence_feature_GLOVE)\n",
        "s3=pd.DataFrame(sentence_feature_GLOVE25)\n",
        "s4=pd.DataFrame(sentence_feature_GLOVE50)\n",
        "s5=pd.DataFrame(sentence_feature_GLOVE100)\n",
        "s6=pd.DataFrame(sentence_feature_tweet)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s0.reset_index(drop=True,inplace=True)\n",
        "s3.reset_index(drop=True,inplace=True)\n",
        "s2.reset_index(drop=True,inplace=True)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s5.reset_index(drop=True,inplace=True)\n",
        "s6.reset_index(drop=True,inplace=True)\n",
        "\n",
        "\n",
        "sentence_feature_normal_new=pd.concat([s1,s0],axis=1)\n",
        "sentence_feature_tweet_new=pd.concat([s6,s0],axis=1)\n",
        "sentence_feature_GLOVE_new=pd.concat([s2,s0],axis=1)\n",
        "sentence_feature_GLOVE25_new=pd.concat([s3,s0],axis=1)\n",
        "sentence_feature_GLOVE50_new=pd.concat([s4,s0],axis=1)\n",
        "sentence_feature_GLOVE100_new=pd.concat([s5,s0],axis=1)\n",
        "\n",
        "\n",
        "sentence_feature_normal_new=sentence_feature_normal_new.to_numpy()\n",
        "sentence_feature_tweet_new=sentence_feature_tweet_new.to_numpy()\n",
        "sentence_feature_GLOVE_new=sentence_feature_GLOVE_new.to_numpy()\n",
        "sentence_feature_GLOVE25_new=sentence_feature_GLOVE25_new.to_numpy()\n",
        "sentence_feature_GLOVE50_new=sentence_feature_GLOVE50_new.to_numpy()\n",
        "sentence_feature_GLOVE100_new=sentence_feature_GLOVE100_new.to_numpy()\n",
        "\n",
        "sentence_feature_GLOVE.shape"
      ],
      "metadata": {
        "id": "4Qd7Zcgz972G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc81dc97-a8a3-44ca-f155-3df4068603c0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated run settings "
      ],
      "metadata": {
        "id": "0orvks3hvHB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reps_dict={\n",
        "    \"BERT_pca\":sentence_feature_normal,\n",
        "    \"tweetBERT_pca\":sentence_feature_tweet,\n",
        "    \"GLOVE_pca\":sentence_feature_GLOVE,\n",
        "    \"GLOVE50_pca\":sentence_feature_GLOVE25,\n",
        "    \"GLOVE25_pca\":sentence_feature_GLOVE50,\n",
        "    \"GLOVE100_pca\":sentence_feature_GLOVE100,\n",
        "    \"BERT_pca_concat\":sentence_feature_normal_new,\n",
        "    \"tweetBERT_pca_concat\":sentence_feature_tweet_new,\n",
        "    \"GLOVE_pca_concat\":sentence_feature_GLOVE_new,\n",
        "    \"GLOVE50_pca_concat\":sentence_feature_GLOVE25_new,\n",
        "    \"GLOVE25_pca_concat\":sentence_feature_GLOVE50_new,\n",
        "    \"GLOVE100_pca_concat\":sentence_feature_GLOVE100_new,\n",
        "}"
      ],
      "metadata": {
        "id": "X34iBzQ-903X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJKSPedcge3"
      },
      "source": [
        "number_of_run = 5\n",
        "def AL_loop(rep,model,AL_stg):\n",
        "  \n",
        "  sentence_feature=reps_dict[rep]\n",
        "  data_test = sentence_feature[train_start:train_end+1]\n",
        "  strat = uncertainty_sampling\n",
        "  \n",
        "  if AL_stg==\"lc\": stg=False\n",
        "\n",
        "  if AL_stg==\"Random\": stg=True\n",
        "\n",
        "  if AL_stg==\"batch_lc\":\n",
        "    stg=False\n",
        "    strat = uncertainty_batch_sampling\n",
        "\n",
        "  if AL_stg==\"qbc\"or AL_stg=='boost' or AL_stg=='bag':\n",
        "    stg=False\n",
        "    print(AL_stg,'   ',rep,'    ',model)\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_commite(50,data_test, test_labels,number_of_run,model,strat,20,stg,AL_stg)\n",
        "  \n",
        "  if model==\"mlp\":\n",
        "    if rep!= \"GLOVE_pca_concat\":\n",
        "      print(model)\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy(50, data_test, test_labels,number_of_run,create_keras_model_berts,strat,20,stg)\n",
        "    else:\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy(50, data_test, test_labels,number_of_run,create_keras_model_GLOVE,strat,20,stg)  \n",
        "  elif AL_stg==\"epsilon_in_batch\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_epsilon_greedy(50,data_test, test_labels,number_of_run,model,strat,20,False)\n",
        "  elif AL_stg==\"epsilon_in_batch_rand\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_epsilon_greedy(50,data_test, test_labels,number_of_run,model,strat,20,True)\n",
        "  elif AL_stg==\"cross\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_cross(50,data_test, test_labels,number_of_run,model,strat,20,False)\n",
        "  elif AL_stg!=\"qbc\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_sklearn(50,data_test, test_labels,number_of_run,model,strat,20,stg)\n",
        "\n",
        "  return acc,f1,pref_random,pref_hist_majority,N_QUERIES \n",
        "  "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnwh_r6Wk4C"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# counter = 0\n",
        "# reps = ['GLOVE']\n",
        "# models = ['LR']\n",
        "# stratefies = ['lc'] \n",
        "\n",
        "# for rep in reps:\n",
        "#   for model in models:\n",
        "#     for AL_stg in stratefies:\n",
        "#       counter = counter+1\n",
        "#       acc,f1,pref_random,pref_hist_majority,N_QUERIES = AL_loop(rep,model,AL_stg)\n",
        " "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final run with different AL settings with Automated run setting set in previous section"
      ],
      "metadata": {
        "id": "uEAnmeRCu8Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "counter = 0\n",
        "reps = ['tweetBERT_pca_concat']\n",
        "models = ['LR']\n",
        "stratefies = ['lc'] \n",
        "\n",
        "for rep in reps:\n",
        "  for model in models:\n",
        "    for AL_stg in stratefies:\n",
        "      counter = counter+1\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = AL_loop(rep,model,AL_stg)"
      ],
      "metadata": {
        "id": "OuyZ0HMm6QM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef70f26-8b36-4335-bb02-6d3b28387c29"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 th run and query number 1\n",
            "num if query 50\n",
            "after query 2: Accuracy :0.8485 macro f1 :0.7824\n",
            "0:00:00\n",
            "0 th run and query number 2\n",
            "num if query 50\n",
            "after query 3: Accuracy :0.8214 macro f1 :0.7409\n",
            "0:00:00\n",
            "0 th run and query number 3\n",
            "num if query 50\n",
            "after query 4: Accuracy :0.8359 macro f1 :0.7586\n",
            "0:00:00\n",
            "0 th run and query number 4\n",
            "num if query 50\n",
            "after query 5: Accuracy :0.8359 macro f1 :0.7562\n",
            "0:00:00\n",
            "0 th run and query number 5\n",
            "num if query 50\n",
            "after query 6: Accuracy :0.8417 macro f1 :0.7641\n",
            "0:00:00\n",
            "0 th run and query number 6\n",
            "num if query 50\n",
            "after query 7: Accuracy :0.8447 macro f1 :0.7657\n",
            "0:00:00\n",
            "0 th run and query number 7\n",
            "num if query 50\n",
            "after query 8: Accuracy :0.8447 macro f1 :0.7680\n",
            "0:00:00\n",
            "0 th run and query number 8\n",
            "num if query 50\n",
            "after query 9: Accuracy :0.8456 macro f1 :0.7706\n",
            "0:00:00\n",
            "0 th run and query number 9\n",
            "num if query 50\n",
            "after query 10: Accuracy :0.8427 macro f1 :0.7697\n",
            "0:00:00\n",
            "0 th run and query number 10\n",
            "num if query 50\n",
            "after query 11: Accuracy :0.8427 macro f1 :0.7774\n",
            "0:00:00\n",
            "0 th run and query number 11\n",
            "num if query 50\n",
            "after query 12: Accuracy :0.8417 macro f1 :0.7777\n",
            "0:00:00\n",
            "0 th run and query number 12\n",
            "num if query 50\n",
            "after query 13: Accuracy :0.8369 macro f1 :0.7757\n",
            "0:00:00\n",
            "0 th run and query number 13\n",
            "num if query 50\n",
            "after query 14: Accuracy :0.8340 macro f1 :0.7751\n",
            "0:00:00\n",
            "0 th run and query number 14\n",
            "num if query 50\n",
            "after query 15: Accuracy :0.8330 macro f1 :0.7753\n",
            "0:00:00\n",
            "0 th run and query number 15\n",
            "num if query 50\n",
            "after query 16: Accuracy :0.8320 macro f1 :0.7755\n",
            "0:00:00\n",
            "0 th run and query number 16\n",
            "num if query 50\n",
            "after query 17: Accuracy :0.8282 macro f1 :0.7709\n",
            "0:00:00\n",
            "0 th run and query number 17\n",
            "num if query 50\n",
            "after query 18: Accuracy :0.8311 macro f1 :0.7779\n",
            "0:00:00\n",
            "0 th run and query number 18\n",
            "num if query 50\n",
            "after query 19: Accuracy :0.8350 macro f1 :0.7846\n",
            "0:00:00\n",
            "0 th run and query number 19\n",
            "num if query 50\n",
            "after query 20: Accuracy :0.8320 macro f1 :0.7821\n",
            "0:00:00\n",
            "0 th run and query number 20\n",
            "num if query 50\n",
            "after query 21: Accuracy :0.8282 macro f1 :0.7787\n",
            "0:00:00\n",
            "0:00:04\n",
            "1 th run and query number 1\n",
            "num if query 50\n",
            "after query 2: Accuracy :0.8456 macro f1 :0.7825\n",
            "0:00:00\n",
            "1 th run and query number 2\n",
            "num if query 50\n",
            "after query 3: Accuracy :0.8417 macro f1 :0.7850\n",
            "0:00:00\n",
            "1 th run and query number 3\n",
            "num if query 50\n",
            "after query 4: Accuracy :0.8417 macro f1 :0.7845\n",
            "0:00:00\n",
            "1 th run and query number 4\n",
            "num if query 50\n",
            "after query 5: Accuracy :0.8476 macro f1 :0.7952\n",
            "0:00:00\n",
            "1 th run and query number 5\n",
            "num if query 50\n",
            "after query 6: Accuracy :0.8505 macro f1 :0.7988\n",
            "0:00:00\n",
            "1 th run and query number 6\n",
            "num if query 50\n",
            "after query 7: Accuracy :0.8485 macro f1 :0.7951\n",
            "0:00:00\n",
            "1 th run and query number 7\n",
            "num if query 50\n",
            "after query 8: Accuracy :0.8495 macro f1 :0.7939\n",
            "0:00:00\n",
            "1 th run and query number 8\n",
            "num if query 50\n",
            "after query 9: Accuracy :0.8505 macro f1 :0.7955\n",
            "0:00:00\n",
            "1 th run and query number 9\n",
            "num if query 50\n",
            "after query 10: Accuracy :0.8495 macro f1 :0.7945\n",
            "0:00:00\n",
            "1 th run and query number 10\n",
            "num if query 50\n",
            "after query 11: Accuracy :0.8583 macro f1 :0.8067\n",
            "0:00:00\n",
            "1 th run and query number 11\n",
            "num if query 50\n",
            "after query 12: Accuracy :0.8524 macro f1 :0.8004\n",
            "0:00:00\n",
            "1 th run and query number 12\n",
            "num if query 50\n",
            "after query 13: Accuracy :0.8534 macro f1 :0.8019\n",
            "0:00:00\n",
            "1 th run and query number 13\n",
            "num if query 50\n",
            "after query 14: Accuracy :0.8495 macro f1 :0.7961\n",
            "0:00:00\n",
            "1 th run and query number 14\n",
            "num if query 50\n",
            "after query 15: Accuracy :0.8466 macro f1 :0.7941\n",
            "0:00:00\n",
            "1 th run and query number 15\n",
            "num if query 50\n",
            "after query 16: Accuracy :0.8427 macro f1 :0.7916\n",
            "0:00:00\n",
            "1 th run and query number 16\n",
            "num if query 50\n",
            "after query 17: Accuracy :0.8427 macro f1 :0.7927\n",
            "0:00:00\n",
            "1 th run and query number 17\n",
            "num if query 50\n",
            "after query 18: Accuracy :0.8398 macro f1 :0.7896\n",
            "0:00:00\n",
            "1 th run and query number 18\n",
            "num if query 50\n",
            "after query 19: Accuracy :0.8359 macro f1 :0.7861\n",
            "0:00:00\n",
            "1 th run and query number 19\n",
            "num if query 50\n",
            "after query 20: Accuracy :0.8359 macro f1 :0.7866\n",
            "0:00:00\n",
            "1 th run and query number 20\n",
            "num if query 50\n",
            "after query 21: Accuracy :0.8320 macro f1 :0.7826\n",
            "0:00:00\n",
            "0:00:02\n",
            "2 th run and query number 1\n",
            "num if query 50\n",
            "after query 2: Accuracy :0.8301 macro f1 :0.7774\n",
            "0:00:00\n",
            "2 th run and query number 2\n",
            "num if query 50\n",
            "after query 3: Accuracy :0.8437 macro f1 :0.7987\n",
            "0:00:00\n",
            "2 th run and query number 3\n",
            "num if query 50\n",
            "after query 4: Accuracy :0.8544 macro f1 :0.8104\n",
            "0:00:00\n",
            "2 th run and query number 4\n",
            "num if query 50\n",
            "after query 5: Accuracy :0.8592 macro f1 :0.8169\n",
            "0:00:00\n",
            "2 th run and query number 5\n",
            "num if query 50\n",
            "after query 6: Accuracy :0.8631 macro f1 :0.8193\n",
            "0:00:00\n",
            "2 th run and query number 6\n",
            "num if query 50\n",
            "after query 7: Accuracy :0.8631 macro f1 :0.8189\n",
            "0:00:00\n",
            "2 th run and query number 7\n",
            "num if query 50\n",
            "after query 8: Accuracy :0.8650 macro f1 :0.8205\n",
            "0:00:00\n",
            "2 th run and query number 8\n",
            "num if query 50\n",
            "after query 9: Accuracy :0.8621 macro f1 :0.8155\n",
            "0:00:00\n",
            "2 th run and query number 9\n",
            "num if query 50\n",
            "after query 10: Accuracy :0.8689 macro f1 :0.8234\n",
            "0:00:00\n",
            "2 th run and query number 10\n",
            "num if query 50\n",
            "after query 11: Accuracy :0.8641 macro f1 :0.8181\n",
            "0:00:00\n",
            "2 th run and query number 11\n",
            "num if query 50\n",
            "after query 12: Accuracy :0.8592 macro f1 :0.8137\n",
            "0:00:00\n",
            "2 th run and query number 12\n",
            "num if query 50\n",
            "after query 13: Accuracy :0.8583 macro f1 :0.8117\n",
            "0:00:00\n",
            "2 th run and query number 13\n",
            "num if query 50\n",
            "after query 14: Accuracy :0.8553 macro f1 :0.8091\n",
            "0:00:00\n",
            "2 th run and query number 14\n",
            "num if query 50\n",
            "after query 15: Accuracy :0.8495 macro f1 :0.8053\n",
            "0:00:00\n",
            "2 th run and query number 15\n",
            "num if query 50\n",
            "after query 16: Accuracy :0.8466 macro f1 :0.8017\n",
            "0:00:00\n",
            "2 th run and query number 16\n",
            "num if query 50\n",
            "after query 17: Accuracy :0.8466 macro f1 :0.8027\n",
            "0:00:00\n",
            "2 th run and query number 17\n",
            "num if query 50\n",
            "after query 18: Accuracy :0.8437 macro f1 :0.7996\n",
            "0:00:00\n",
            "2 th run and query number 18\n",
            "num if query 50\n",
            "after query 19: Accuracy :0.8398 macro f1 :0.7951\n",
            "0:00:00\n",
            "2 th run and query number 19\n",
            "num if query 50\n",
            "after query 20: Accuracy :0.8408 macro f1 :0.7961\n",
            "0:00:00\n",
            "2 th run and query number 20\n",
            "num if query 50\n",
            "after query 21: Accuracy :0.8437 macro f1 :0.8001\n",
            "0:00:00\n",
            "0:00:02\n",
            "3 th run and query number 1\n",
            "num if query 50\n",
            "after query 2: Accuracy :0.8388 macro f1 :0.7820\n",
            "0:00:00\n",
            "3 th run and query number 2\n",
            "num if query 50\n",
            "after query 3: Accuracy :0.8291 macro f1 :0.7753\n",
            "0:00:00\n",
            "3 th run and query number 3\n",
            "num if query 50\n",
            "after query 4: Accuracy :0.8398 macro f1 :0.7902\n",
            "0:00:00\n",
            "3 th run and query number 4\n",
            "num if query 50\n",
            "after query 5: Accuracy :0.8350 macro f1 :0.7830\n",
            "0:00:00\n",
            "3 th run and query number 5\n",
            "num if query 50\n",
            "after query 6: Accuracy :0.8379 macro f1 :0.7871\n",
            "0:00:00\n",
            "3 th run and query number 6\n",
            "num if query 50\n",
            "after query 7: Accuracy :0.8311 macro f1 :0.7784\n",
            "0:00:00\n",
            "3 th run and query number 7\n",
            "num if query 50\n",
            "after query 8: Accuracy :0.8282 macro f1 :0.7738\n",
            "0:00:00\n",
            "3 th run and query number 8\n",
            "num if query 50\n",
            "after query 9: Accuracy :0.8311 macro f1 :0.7756\n",
            "0:00:00\n",
            "3 th run and query number 9\n",
            "num if query 50\n",
            "after query 10: Accuracy :0.8291 macro f1 :0.7753\n",
            "0:00:00\n",
            "3 th run and query number 10\n",
            "num if query 50\n",
            "after query 11: Accuracy :0.8175 macro f1 :0.7646\n",
            "0:00:00\n",
            "3 th run and query number 11\n",
            "num if query 50\n",
            "after query 12: Accuracy :0.8194 macro f1 :0.7682\n",
            "0:00:00\n",
            "3 th run and query number 12\n",
            "num if query 50\n",
            "after query 13: Accuracy :0.8194 macro f1 :0.7699\n",
            "0:00:00\n",
            "3 th run and query number 13\n",
            "num if query 50\n",
            "after query 14: Accuracy :0.8107 macro f1 :0.7579\n",
            "0:00:00\n",
            "3 th run and query number 14\n",
            "num if query 50\n",
            "after query 15: Accuracy :0.8097 macro f1 :0.7575\n",
            "0:00:00\n",
            "3 th run and query number 15\n",
            "num if query 50\n",
            "after query 16: Accuracy :0.8097 macro f1 :0.7602\n",
            "0:00:00\n",
            "3 th run and query number 16\n",
            "num if query 50\n",
            "after query 17: Accuracy :0.8058 macro f1 :0.7569\n",
            "0:00:00\n",
            "3 th run and query number 17\n",
            "num if query 50\n",
            "after query 18: Accuracy :0.8087 macro f1 :0.7608\n",
            "0:00:00\n",
            "3 th run and query number 18\n",
            "num if query 50\n",
            "after query 19: Accuracy :0.8087 macro f1 :0.7608\n",
            "0:00:00\n",
            "3 th run and query number 19\n",
            "num if query 50\n",
            "after query 20: Accuracy :0.8049 macro f1 :0.7575\n",
            "0:00:00\n",
            "3 th run and query number 20\n",
            "num if query 50\n",
            "after query 21: Accuracy :0.8058 macro f1 :0.7580\n",
            "0:00:00\n",
            "0:00:03\n",
            "4 th run and query number 1\n",
            "num if query 50\n",
            "after query 2: Accuracy :0.8175 macro f1 :0.7531\n",
            "0:00:00\n",
            "4 th run and query number 2\n",
            "num if query 50\n",
            "after query 3: Accuracy :0.8175 macro f1 :0.7432\n",
            "0:00:00\n",
            "4 th run and query number 3\n",
            "num if query 50\n",
            "after query 4: Accuracy :0.8330 macro f1 :0.7657\n",
            "0:00:00\n",
            "4 th run and query number 4\n",
            "num if query 50\n",
            "after query 5: Accuracy :0.8301 macro f1 :0.7627\n",
            "0:00:00\n",
            "4 th run and query number 5\n",
            "num if query 50\n",
            "after query 6: Accuracy :0.8301 macro f1 :0.7634\n",
            "0:00:00\n",
            "4 th run and query number 6\n",
            "num if query 50\n",
            "after query 7: Accuracy :0.8262 macro f1 :0.7551\n",
            "0:00:00\n",
            "4 th run and query number 7\n",
            "num if query 50\n",
            "after query 8: Accuracy :0.8340 macro f1 :0.7661\n",
            "0:00:00\n",
            "4 th run and query number 8\n",
            "num if query 50\n",
            "after query 9: Accuracy :0.8398 macro f1 :0.7722\n",
            "0:00:00\n",
            "4 th run and query number 9\n",
            "num if query 50\n",
            "after query 10: Accuracy :0.8388 macro f1 :0.7732\n",
            "0:00:00\n",
            "4 th run and query number 10\n",
            "num if query 50\n",
            "after query 11: Accuracy :0.8408 macro f1 :0.7792\n",
            "0:00:00\n",
            "4 th run and query number 11\n",
            "num if query 50\n",
            "after query 12: Accuracy :0.8388 macro f1 :0.7790\n",
            "0:00:00\n",
            "4 th run and query number 12\n",
            "num if query 50\n",
            "after query 13: Accuracy :0.8359 macro f1 :0.7783\n",
            "0:00:00\n",
            "4 th run and query number 13\n",
            "num if query 50\n",
            "after query 14: Accuracy :0.8388 macro f1 :0.7854\n",
            "0:00:00\n",
            "4 th run and query number 14\n",
            "num if query 50\n",
            "after query 15: Accuracy :0.8447 macro f1 :0.7947\n",
            "0:00:00\n",
            "4 th run and query number 15\n",
            "num if query 50\n",
            "after query 16: Accuracy :0.8398 macro f1 :0.7902\n",
            "0:00:00\n",
            "4 th run and query number 16\n",
            "num if query 50\n",
            "after query 17: Accuracy :0.8388 macro f1 :0.7902\n",
            "0:00:00\n",
            "4 th run and query number 17\n",
            "num if query 50\n",
            "after query 18: Accuracy :0.8408 macro f1 :0.7927\n",
            "0:00:00\n",
            "4 th run and query number 18\n",
            "num if query 50\n",
            "after query 19: Accuracy :0.8359 macro f1 :0.7861\n",
            "0:00:00\n",
            "4 th run and query number 19\n",
            "num if query 50\n",
            "after query 20: Accuracy :0.8359 macro f1 :0.7866\n",
            "0:00:00\n",
            "4 th run and query number 20\n",
            "num if query 50\n",
            "after query 21: Accuracy :0.8330 macro f1 :0.7831\n",
            "0:00:00\n",
            "0:00:02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnVxfd3syJBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b966fd7-a552-46c0-9378-4bcf8040aace"
      },
      "source": [
        "acc_25perc_avg=acc[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "f1_25perc_avg=f1[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "\n",
        "# print(acc25_avg[-1])\n",
        "print(f1_25perc_avg[-1])  \n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.782794136320921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embedding\n",
        "Word embedding generation in case we don't want to used the pretrained saved models that was trained previously and saved on Github.\n",
        "The save representations on Github were made by code below."
      ],
      "metadata": {
        "id": "T_5DIrR4sEV-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZySdeJ5Icv-"
      },
      "source": [
        "### selecting test train eval set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jCWJyUcJthA"
      },
      "source": [
        "#### 0's topic test and rest train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWGCON7lwK_"
      },
      "source": [
        "data_cp =data"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJO8UF-pk-Eu"
      },
      "source": [
        "topic_num = 1"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCOpzX96IsrG",
        "outputId": "92aa47f6-f8bf-4764-bff9-1f922324f6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_df = data[data['topic']==topic_num]\n",
        "train_df = data[data['topic']!=topic_num]\n",
        "train_df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                 text  tag  \\\n",
              "553529101659566080  BREAKING: Armed man takes hostage in kosher gr...    1   \n",
              "553587735613952001  #CharlieHebdo killers dead, confirmed by genda...    1   \n",
              "552816932643405824  Top French cartoonists Charb, Cabu, Wolinski, ...    1   \n",
              "553515399438811136  Police have surrounded the area where the #Cha...    1   \n",
              "552808620187217920  PHOTO: Armed gunmen face police officers near ...    1   \n",
              "\n",
              "                   favorite_count_log retweet_count  verified followers  \\\n",
              "553529101659566080           0.227244      0.415037         1  0.007659   \n",
              "553587735613952001            0.28816       0.38947         0  0.000186   \n",
              "552816932643405824           0.266684      0.398594         0  0.000806   \n",
              "553515399438811136           0.486626      0.539645         1  0.608823   \n",
              "552808620187217920           0.279619      0.373837         1  0.033286   \n",
              "\n",
              "                   follow_ratio    length capital_ratio question_mark  \\\n",
              "553529101659566080     0.000089  0.525926      0.002136             0   \n",
              "553587735613952001     0.000004  0.266667      0.000395             0   \n",
              "552816932643405824      0.00001  0.881481      0.000844             0   \n",
              "553515399438811136     0.004195  0.896296      0.001295             0   \n",
              "552808620187217920     0.000517  0.740741      0.002053             0   \n",
              "\n",
              "                   exclamation_point has_emoji hashtag_count has_url  \\\n",
              "553529101659566080                 0         0             0       1   \n",
              "553587735613952001                 0         0             1       0   \n",
              "552816932643405824                 0         0             2       0   \n",
              "553515399438811136                 0         0             1       1   \n",
              "552808620187217920                 0         0             1       1   \n",
              "\n",
              "                    media_type  topic  \n",
              "553529101659566080           0      0  \n",
              "553587735613952001           0      0  \n",
              "552816932643405824           0      0  \n",
              "553515399438811136           0      0  \n",
              "552808620187217920           1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2188f89f-065c-439c-adeb-d3a8f746a021\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "      <th>favorite_count_log</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>verified</th>\n",
              "      <th>followers</th>\n",
              "      <th>follow_ratio</th>\n",
              "      <th>length</th>\n",
              "      <th>capital_ratio</th>\n",
              "      <th>question_mark</th>\n",
              "      <th>exclamation_point</th>\n",
              "      <th>has_emoji</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>has_url</th>\n",
              "      <th>media_type</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>553529101659566080</th>\n",
              "      <td>BREAKING: Armed man takes hostage in kosher gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.227244</td>\n",
              "      <td>0.415037</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007659</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.525926</td>\n",
              "      <td>0.002136</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553587735613952001</th>\n",
              "      <td>#CharlieHebdo killers dead, confirmed by genda...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.28816</td>\n",
              "      <td>0.38947</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552816932643405824</th>\n",
              "      <td>Top French cartoonists Charb, Cabu, Wolinski, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.266684</td>\n",
              "      <td>0.398594</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.881481</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553515399438811136</th>\n",
              "      <td>Police have surrounded the area where the #Cha...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.486626</td>\n",
              "      <td>0.539645</td>\n",
              "      <td>1</td>\n",
              "      <td>0.608823</td>\n",
              "      <td>0.004195</td>\n",
              "      <td>0.896296</td>\n",
              "      <td>0.001295</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552808620187217920</th>\n",
              "      <td>PHOTO: Armed gunmen face police officers near ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.279619</td>\n",
              "      <td>0.373837</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033286</td>\n",
              "      <td>0.000517</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2188f89f-065c-439c-adeb-d3a8f746a021')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2188f89f-065c-439c-adeb-d3a8f746a021 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2188f89f-065c-439c-adeb-d3a8f746a021');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqvHai1elpta",
        "outputId": "5154708e-88b3-4155-ec87-0384a03ff85d"
      },
      "source": [
        "data2=data.reset_index()\n",
        "start_test=data2[data2['topic']==topic_num].iloc[0]\n",
        "# end_test=data2[data2['topic']==0].iloc[-1]\n",
        "# start_train =data2[data2['topic']==1].iloc[0]\n",
        "# end_train = start_test=data2[data2['topic']==8].iloc[-1]\n",
        "def pd_iter_func(df,topic):\n",
        "    for row in df.itertuples():\n",
        "        # Define your criteria here\n",
        "        if row.topic ==topic:\n",
        "            return row\n",
        "start_test=pd_iter_func(data2,1).Index\n",
        "end_test = pd_iter_func(data2,2).Index-1\n",
        "train_start = pd_iter_func(data2,topic_num).Index\n",
        "train_end = len(data2)\n",
        "print(start_test,',',end_test)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2079 , 2092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcvb0IhoJ07V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0371fe5-6020-4895-c197-577da4504642"
      },
      "source": [
        "train_sentences = train_df.text.values\n",
        "test_sentences = test_df.text.values\n",
        "train_labels = train_df.tag.values\n",
        "test_labels = test_df.tag.values\n",
        "len(train_labels)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6411"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5MU4IIbsIC"
      },
      "source": [
        "#####over ride just 0 test and train for now\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVzNdJ46brdd"
      },
      "source": [
        "test_labels = test_df.tag.values\n",
        "train_start=0\n",
        "train_end=2078"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-esnaFdhBBS"
      },
      "source": [
        "### Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfWqiX7gYKI"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBU_Qv1muGQW"
      },
      "source": [
        "sentence_feature=np.load('/content/sentiment_new_approach/vectorization/normal_bert.npy')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBnCn3fRo4JS"
      },
      "source": [
        "sentence_feature=np.load('/content/sentiment_new_approach/vectorization/tweet_bert.npy')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXO_4GCgbjH7",
        "outputId": "e26f7843-cbee-497a-a115-d3ba7ebccc93"
      },
      "source": [
        "sentence_feature.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSfeIiaoeFJ",
        "outputId": "122b8537-39eb-4a2d-bc83-04b84fed56dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install emoji\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oQ61gE0pnZL",
        "outputId": "1177485e-4cb4-4336-bbd6-7e529c69eee3"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer \n",
        "# Load BERT TWEET tokenizer and model\n",
        "bert_tweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "tokenizer_tweet = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\",normalization=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1z0rI5FNVL"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "def tokenizer_func(tokenizer_kind,sentences,labels):\n",
        "  '''\n",
        "  inputs:\n",
        "    tokenizer_kind: is the the tokenizer of choice (normal bert, tweet bert)  \n",
        "    sentences: train , dev, test\n",
        "  outputs:\n",
        "  torchs of \n",
        "    ids\n",
        "    attention_mask\n",
        "    labels\n",
        "  '''\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer_kind.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          truncation=True,\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  return input_ids, attention_masks ,labels\n",
        "  # Print sentence 0, now as a list of IDs.\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PO4WiaOFU01",
        "outputId": "1befe0a6-edfa-47f2-912c-b86de95f821a"
      },
      "source": [
        "sentences = data.text.values\n",
        "train_labels = data.tag.values\n",
        "input_ids,attention_masks,labels=tokenizer_func(tokenizer_tweet,sentences,train_labels)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYB5FSknIx_u"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset\n",
        "batch_size=128\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSSKkuwzSJI4",
        "outputId": "9bf76546-9432-47a1-f574-b6924eb4dc80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bert_tweet.cuda()\n",
        "bert_tweet.eval()\n",
        "# Tracking variables \n",
        "sentence_feature=[]\n",
        "t1 = time.time()\n",
        "for batch in prediction_dataloader:\n",
        "  t0 = time.time()  \n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = bert_tweet(b_input_ids, attention_mask=b_input_mask)\n",
        "      \n",
        "  sentence_features_slice = outputs[0][:,0,:].cpu().numpy()  \n",
        "  # Store predictions and true labels\n",
        "  sentence_feature.append(sentence_features_slice)\n",
        "  elapsed = format_time(time.time() - t0)\n",
        "  print(\"time elapse:\",elapsed)\n",
        "print(\"full time\",format_time(time.time()-t1))\n",
        "sentence_feature = np.concatenate(sentence_feature, axis=0)\n",
        "print(sentence_feature.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:01\n",
            "time elapse: 0:00:00\n",
            "full time 0:00:41\n",
            "(6425, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZCCzuZFGqow"
      },
      "source": [
        "\n",
        "with open('tweet_bert.npy', 'wb') as f:\n",
        "    np.save(f, sentence_feature)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsMJxBOXffm"
      },
      "source": [
        "#### Glove word embeding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3pjS7AaCiO_"
      },
      "source": [
        "##### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VJe6hrBCrC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb305a42-cfd6-45e2-ae98-1a6d2eadf147"
      },
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Change \"@name\" to \"Username\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    - change urls to \"Link\"\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Change \"@name\" to \"Username\n",
        "    s = re.sub(r'(@.*?)[\\s]', 'username', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    # change urls to \"Link\"\n",
        "    s = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",'link',s)\n",
        "    \n",
        "    return s"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jknz7wXACuzy"
      },
      "source": [
        "import numpy as np\n",
        "sentences = np.array([text_preprocessing(text) for text in data.text.values  ])\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsqrqPZpT9bp"
      },
      "source": [
        "#####Glove\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hylGOHjyL5Ic",
        "outputId": "91f65779-9fb2-49cc-de3f-edbfbbb46e75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYotFrQnaFr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df304e35-ac57-4bc5-93ce-1e285d6fbdbc"
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/glove.twitter.27B.zip\""
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/gdrive/My Drive/glove.twitter.27B.zip, /content/gdrive/My Drive/glove.twitter.27B.zip.zip or /content/gdrive/My Drive/glove.twitter.27B.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv59vXazjpqB"
      },
      "source": [
        "def loadGloveModel(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(File,'r')\n",
        "    gloveModel = {}\n",
        "    for line in f:\n",
        "        splitLines = line.split()\n",
        "        word = splitLines[0]\n",
        "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "        gloveModel[word] = wordEmbedding\n",
        "    print(len(gloveModel),\" words loaded!\")\n",
        "    return gloveModel\n",
        "glove = loadGloveModel('glove.twitter.27B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UePgEF3o8zY"
      },
      "source": [
        "\n",
        "data_train = np.zeros(shape=(len(sentences),50),dtype=np.float)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  tweet = sentences[i]\n",
        "  tweet = tweet.split(' ')\n",
        "  glove_word_count = 1\n",
        "  for word in tweet:\n",
        "    if word.lower() in glove:\n",
        "      glove_word_count +=1\n",
        "      data_train[i,:]+= glove[word]\n",
        "  data_train[i,:]=data_train[i,:]/(glove_word_count)\n",
        "features=data_train\n",
        "#representation Glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwDjsrB3lBRA"
      },
      "source": [
        "sentence_feature_GLOVE=features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54Zd_3dvLRY"
      },
      "source": [
        "sentence_feature_GLOVE.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBghjd46vsCu"
      },
      "source": [
        "save_reesult(sentence_feature_GLOVE,'GLOVE50.np')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}