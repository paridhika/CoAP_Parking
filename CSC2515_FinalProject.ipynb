{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/CoAP_Parking/blob/master/CSC2515_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8loDujPQPhrq"
      },
      "source": [
        "# Active Transfer Learning\n",
        "\n",
        "In this project we experiment different active learning setups. To run the code with "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfJnQ9-7yl8O"
      },
      "source": [
        "## Importing and setting GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0-Xc4Y1mq0U"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "!pip install transformers\n",
        "!pip install scikeras[tensorflow]\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib inline\n",
        "import json\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "!pip install modAL\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7xhV_DPAz5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMhaZEKEPIJ2"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "WkSkme4-1QMe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKg1VPGPgL6"
      },
      "source": [
        "## Loading and preprocessing data :\n",
        "We can either use the preprocess data fetched from my Github repo or them in the last section then running these cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8dAuAY1aTk6",
        "outputId": "039fbc48-5c63-40f1-c45b-1bd4eec0bb32"
      },
      "source": [
        "!git clone \"https://github.com/parsafarinnia/sentiment_new_approach\"\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentiment_new_approach'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 75 (delta 20), reused 42 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), 55.86 MiB | 5.65 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOcePxwdUjcd"
      },
      "source": [
        "topic_num=0\n",
        "\n",
        "all_topics = pickle.load(open(\"/content/sentiment_new_approach/all_topics_with_meta.p\",\"rb\"))\n",
        "data=pd.DataFrame.from_dict(all_topics[0]).T\n",
        "data['topic']=0\n",
        "tags = data.tag.values\n",
        "\n",
        "for i in range(1,9):\n",
        "  topic = pd.DataFrame.from_dict(all_topics[i]).T\n",
        "  topic['topic'] = i\n",
        "  data = pd.concat([data,topic],axis=0)\n",
        "\n",
        "\n",
        "#Converting boolean features into integers in the dataset\n",
        "map={\"rumours\":1,\"non-rumours\":0}\n",
        "data=data.replace({'tag':map})\n",
        "map={\"photo\":1,\"none\":0}\n",
        "data=data.replace({'media_type':map})\n",
        "map={True:1,False:0}\n",
        "data=data.replace({'verified':map})\n",
        "\n",
        "\n",
        "#Normalizing features\n",
        "import copy\n",
        "df=copy.deepcopy(data)\n",
        "cols=['favorite_count_log','retweet_count','followers','follow_ratio','length','capital_ratio']\n",
        "for item in cols:\n",
        "  column=item\n",
        "  df[column] = (df[column]-df[column].min()) /(df[column].max()-df[column].min())\n",
        "\n",
        "\n",
        "data=df\n",
        "train_df = data[data['topic']!=topic_num]\n",
        "train_sentences=train_df.text.values\n",
        "train_labels=train_df.tag.values\n",
        "\n",
        "test_df = data[data['topic']==topic_num]\n",
        "test_sentences=test_df.text.values\n",
        "test_labels=test_df.tag.values\n",
        "\n",
        "\n",
        "data2=data.reset_index()\n",
        "def pd_iter_func(df,topic):\n",
        "    for row in df.itertuples():\n",
        "        # Define your criteria here\n",
        "        if row.topic==topic:\n",
        "            return row\n",
        "\n",
        "start_test=pd_iter_func(data2,topic_num).Index\n",
        "\n",
        "if topic_num==8: \n",
        "  end_test=len(data2)\n",
        "else:\n",
        "  end_test=pd_iter_func(data2,topic_num+1).Index-1\n",
        "\n",
        "train_start=start_test\n",
        "train_end=end_test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Active learning multiple runs\n",
        "since every model might have a different input out put and training specific setting we have multiple functions for different model. The Multi part comes from the fact that we need to run the model multiple time to avoid the randomness effect of selecting a specific train test. we do this because our data set is around 2k and we want conrecete results\n"
      ],
      "metadata": {
        "id": "uY0RdW2xskeX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4DI_eYiqIY"
      },
      "source": [
        "###Run_multy_episolon_greedy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "jTs4l8HGIX4h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiW-lOdUiy_j"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def run_multy_epsilon_greedy(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_confusion = np.zeros((num_of_run,N_QUERIES+1,4))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "\n",
        "    clf = get_model(model_name)\n",
        "    \n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "    #Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling).\n",
        "    counter_random= 1 \n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "    pref_confusion[i][0] = [tn, fp, fn, tp]\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      counter_random += 1 \n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      if not is_random:\n",
        "        query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      index_list = range(len(X_pool))\n",
        "      query_index = random.sample(index_list,10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "    \n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting.\n",
        "      tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "      pref_confusion[i][index] = [tn, fp, fn, tp]\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      #Calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r1Z3f4X-lsu"
      },
      "source": [
        "### Run_multy_sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6thIy2-n-qLt"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from keras import utils as np_utils\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy_sklearn(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_confusion = np.zeros((num_of_run,N_QUERIES+1,4))\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "    pref_confusion[i][0] = [tn, fp, fn, tp]\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random : #or counter_random % random_ratio == 0:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "\n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting\n",
        "      tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
        "      pref_confusion[i][index] = [tn, fp, fn, tp]\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      #Calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GAW2YLTWb73"
      },
      "source": [
        "### run_multy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJzQWwYOTHVc"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from keras import utils as np_utils\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy(BATCH_SIZE,data_test,test_labels,num_of_run,model,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test,test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  print(num_of_run,N_QUERIES)\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "\n",
        "  test_labels = keras.utils.np_utils.to_categorical(test_labels, 2)  \n",
        "  \n",
        "  for i in range(num_of_run):\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    clf = KerasClassifier(build_fn=model, epochs=50, batch_size=35, verbose=0)\n",
        "\n",
        "    print('x pool length',X_train.shape)\n",
        "    print('y pool length',y_train.shape)\n",
        "    print(\"Paridhika\")\n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "    print('8888888888888888888888888888888888888888')\n",
        "    print(y_pool[0],y_pool[1],y_pool[2])\n",
        "    print('shapeè',y_pool.shape)\n",
        "  \n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    y_test_cat = np.argmax(y_test,axis=1)\n",
        "    macro=f1_score(y_test_cat,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    y_train_cat = np.argmax(y_test,axis=1)\n",
        "    counts = np.bincount(y_train_cat)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test_cat))]\n",
        "    macro=f1_score( y_test_cat,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "\n",
        "      print('x pool length',len(X_pool))\n",
        "      print('y pool length',len(y_pool))\n",
        "      print(i,'th run and query number',index)\n",
        "      \n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "    \n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      for j in range(5):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "\n",
        "      #Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(data_test, test_labels)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      #y_pred_cat=np.argmax(y_pred)\n",
        "      y_test_cat=np.argmax(y_test,axis=1)\n",
        "      print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score( y_test_cat,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      #Save our model's performance for plotting\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "      # performance_history_acc.append(model_accuracy)\n",
        "      # performance_history_f1.append(macro)\n",
        "      # perf_hist_multy[i][0].append(model_accuracy)\n",
        "      # perf_hist_multy[i][1].append(macro)\n",
        "\n",
        "      #Calculate and add majority\n",
        "      y_train_cat = np.argmax(y_test,axis=1)\n",
        "      counts = np.bincount(y_train_cat)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test_cat))]\n",
        "      macro=f1_score(y_test_cat,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      \n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4Jr0aWQN85"
      },
      "source": [
        "### Run_multy (for pytorch MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeJI2HwTR0t_"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "def run_multy(BATCH_SIZE,data_test,test_labels,num_of_run,model,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test,test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "  print(num_of_run,N_QUERIES)\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "\n",
        "  test_labels = keras.utils.to_categorical(test_labels, 2)  \n",
        "  for i in range(num_of_run):\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    clf = KerasClassifier(model=model)\n",
        "    print('x pool length',X_train.shape)\n",
        "    print('y pool length',y_train.shape)\n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    # Allow our model to query our unlabeled dataset for the most\n",
        "    # informative points according to our query strategy (uncertainty sampling).\n",
        "    \n",
        "    # calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    y_test_cat = np.argmax(y_test,axis=1)\n",
        "    macro=f1_score(y_test_cat,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    # calculate initial batch majority\n",
        "    y_train_cat = np.argmax(y_test,axis=1)\n",
        "    counts = np.bincount(y_train_cat)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "    #calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test_cat))]\n",
        "    macro=f1_score( y_test_cat,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    \n",
        "\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      # print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "      # Teach our ActiveLearner model the record it has requested.\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(5):\n",
        "        learner.teach(X=X, y=y)\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(data_test, test_labels)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      # y_pred_cat=np.argmax(y_pred)\n",
        "      y_test_cat=np.argmax(y_test,axis=1)\n",
        "      # print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score( y_test_cat,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "       # calculate and add majority\n",
        "      y_train_cat = np.argmax(y_test,axis=1)\n",
        "      counts = np.bincount(y_train_cat)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test_cat))]\n",
        "      macro=f1_score(y_test_cat,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      \n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "  return pref_hist_multy_acc_avg,pref_hist_multy_f1_avg ,pref_random,pref_hist_majority_avg#,pref_hist_multy_accuracy,pref_hist_multy_f1\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOYSeV_xX7nt"
      },
      "source": [
        "### run_multy_committe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BksKfnVnX4qn"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from functools import partial\n",
        "import random\n",
        "from modAL.models import ActiveLearner, Committee\n",
        "\n",
        "random_seed_list=[5,12,42,29,54]\n",
        "commite_size = 5\n",
        "\n",
        "def run_multy_commite(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random,mode):\n",
        " \n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "\n",
        "  pref_random = 0\n",
        "  boost = False\n",
        "  if mode=='boost'or mode=='bag':\n",
        "    boost= True\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    learner_list = []\n",
        "    for j in range(commite_size):\n",
        "      learner = ActiveLearner(estimator=clf,query_strategy=preset_batch,X_training=X_train, y_training=y_train,bootstrap_init=boost,)\n",
        "      learner_list.append(learner)\n",
        "\n",
        "    committee = Committee(learner_list=learner_list)\n",
        "    if mode=='bag':\n",
        "      committee.rebag()\n",
        "    t1 = time.time()\n",
        "\n",
        "    # calculate initial batch\n",
        "    y_pred = committee.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #active leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      t2 = time.time()\n",
        "\n",
        "      query_index, query_instance = committee.query(X_pool)\n",
        "\n",
        "      if is_random : #or counter_random % random_ratio == 0:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "    \n",
        "      for j in range(1):\n",
        "        committee.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = committee.score(X_test, y_test)\n",
        "      y_pred = committee.predict(X_test)\n",
        "\n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuaLfSdd36WP"
      },
      "source": [
        "### Run_multy_cross"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddCV-3MT3_BL"
      },
      "source": [
        "def run_multy_cross(BATCH_SIZE,data_test,test_labels,num_of_run,model_name,strategy,train_size,is_random):\n",
        "  test_pool_split=0.5\n",
        "  preset_batch = partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0,y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES = int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority = np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True,random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool,y_pool, test_size=test_pool_split,shuffle=True,random_state=random_seed_list[i])\n",
        "    \n",
        "    learner = ActiveLearner(\n",
        "    estimator=clf,\n",
        "    query_strategy=preset_batch,\n",
        "    X_training=X_train, y_training=y_train)\n",
        "    t1 = time.time()\n",
        "\n",
        "\n",
        "    #Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling)\n",
        "    counter_random= 1 \n",
        "\n",
        "    #Calculate initial batch\n",
        "    y_pred = learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    #Calculate initial batch majority\n",
        "    counts = np.bincount(y_train)\n",
        "    value = np.argmax(counts)\n",
        "    majority =[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    #Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    #Active Leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      counter_random += 1 \n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "      if is_random:\n",
        "        index_list = range(len(X_pool))\n",
        "        query_index = random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      #Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      index_list = range(len(X_pool))\n",
        "      query_index = random.sample(index_list,10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      X_train = np.concatenate((X_train, X))\n",
        "      y_train = np.concatenate((y_train, y))\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "        \n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy = learner.score(X_test, y_test)\n",
        "      y_pred = learner.predict(X_test)\n",
        "      \n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # calculate and add majority\n",
        "      counts = np.bincount(y_train)\n",
        "      value = np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "    print(format_time(time.time()-t1))\n",
        "\n",
        "  pref_random= pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy,pref_hist_multy_f1,pref_random,pref_hist_majority,N_QUERIES"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3jwCE8sQ3Q"
      },
      "source": [
        "###Run_multy for mlp that uses Keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, GlobalMaxPooling1D, Activation\n",
        "from keras.layers import Embedding, LSTM\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "def create_keras_model_berts():\n",
        "  model = Sequential()\n",
        "  model.add(keras.Input(shape=(768,),name=\"source\"))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.3))\n",
        "  # model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def create_keras_model_GLOVE():\n",
        "  model = Sequential()\n",
        "  model.add(keras.Input(shape=(200,),name=\"source\"))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.3))\n",
        "  # model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VepX1HYwd5Ye"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get model\n",
        "getting all generated models that were tested"
      ],
      "metadata": {
        "id": "OuHBSHj33O3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "def get_model(model_name):\n",
        "  if model_name == \"bag\":\n",
        "    clf = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100, max_samples=0.8)\n",
        "  if model_name == \"xgb\":\n",
        "    clf = XGBClassifier()\n",
        "  if model_name == \"gbc\":\n",
        "    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1, max_depth=1)\n",
        "  if model_name ==\"Ada\":\n",
        "    clf = AdaBoostClassifier(n_estimators=200,learning_rate=0.01)\n",
        "  if model_name ==\"svm\":\n",
        "    clf=svm.SVC(probability=True)\n",
        "  if model_name ==\"rf\":\n",
        "    clf=RandomForestClassifier(max_depth=1000, random_state=0)\n",
        "  if model_name ==\"LR\":\n",
        "    clf=LogisticRegression(random_state=0,class_weight='balanced')\n",
        "  if model_name ==\"knn3\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=3)\n",
        "  if model_name ==\"knn5\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=5)\n",
        "  if model_name ==\"gp\":\n",
        "     clf=GaussianProcessClassifier()\n",
        "  if model_name ==\"lda\":\n",
        "    clf=LinearDiscriminantAnalysis()\n",
        "  if model_name ==\"qda\":\n",
        "    clf=QuadraticDiscriminantAnalysis() \n",
        "  return clf"
      ],
      "metadata": {
        "id": "TuYbVoY3_aSC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimension Reduction"
      ],
      "metadata": {
        "id": "6jBdLtbNtueU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence features with PCA\n",
        "Dimension reduction using PCA for all features"
      ],
      "metadata": {
        "id": "8D7yERbQ3WOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "pca=PCA(0.75)\n",
        "sentence_feature_normal=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/normal_bert.npy'))\n",
        "sentence_feature_tweet =pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/tweet_bert.npy'))\n",
        "sentence_feature_GLOVE =pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE.np'))\n",
        "sentence_feature_GLOVE25=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE25.np'))\n",
        "sentence_feature_GLOVE50=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE50.np'))\n",
        "sentence_feature_GLOVE100=pca.fit_transform(np.load('/content/sentiment_new_approach/vectorization/GLOVE100.np'))\n"
      ],
      "metadata": {
        "id": "tJCDwTJD1Mpy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence features with PCA concatenated with metadata"
      ],
      "metadata": {
        "id": "326zohgZ-Pd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s0=data[cols]\n",
        "s1=pd.DataFrame(sentence_feature_normal)\n",
        "s2=pd.DataFrame(sentence_feature_GLOVE)\n",
        "s3=pd.DataFrame(sentence_feature_GLOVE25)\n",
        "s4=pd.DataFrame(sentence_feature_GLOVE50)\n",
        "s5=pd.DataFrame(sentence_feature_GLOVE100)\n",
        "s6=pd.DataFrame(sentence_feature_tweet)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s0.reset_index(drop=True,inplace=True)\n",
        "s3.reset_index(drop=True,inplace=True)\n",
        "s2.reset_index(drop=True,inplace=True)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s5.reset_index(drop=True,inplace=True)\n",
        "s6.reset_index(drop=True,inplace=True)\n",
        "\n",
        "\n",
        "sentence_feature_normal_new=pd.concat([s1,s0],axis=1)\n",
        "sentence_feature_tweet_new=pd.concat([s6,s0],axis=1)\n",
        "sentence_feature_GLOVE_new=pd.concat([s2,s0],axis=1)\n",
        "sentence_feature_GLOVE25_new=pd.concat([s3,s0],axis=1)\n",
        "sentence_feature_GLOVE50_new=pd.concat([s4,s0],axis=1)\n",
        "sentence_feature_GLOVE100_new=pd.concat([s5,s0],axis=1)\n",
        "\n",
        "\n",
        "sentence_feature_normal_new=sentence_feature_normal_new.to_numpy()\n",
        "sentence_feature_tweet_new=sentence_feature_tweet_new.to_numpy()\n",
        "sentence_feature_GLOVE_new=sentence_feature_GLOVE_new.to_numpy()\n",
        "sentence_feature_GLOVE25_new=sentence_feature_GLOVE25_new.to_numpy()\n",
        "sentence_feature_GLOVE50_new=sentence_feature_GLOVE50_new.to_numpy()\n",
        "sentence_feature_GLOVE100_new=sentence_feature_GLOVE100_new.to_numpy()\n",
        "\n",
        "sentence_feature_GLOVE.shape"
      ],
      "metadata": {
        "id": "4Qd7Zcgz972G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985f172c-0c0c-4a6c-afb6-a391a6b7da54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated run settings "
      ],
      "metadata": {
        "id": "0orvks3hvHB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reps_dict={\n",
        "    \"BERT_pca\":sentence_feature_normal,\n",
        "    \"tweetBERT_pca\":sentence_feature_tweet,\n",
        "    \"GLOVE_pca\":sentence_feature_GLOVE,\n",
        "    \"GLOVE50_pca\":sentence_feature_GLOVE25,\n",
        "    \"GLOVE25_pca\":sentence_feature_GLOVE50,\n",
        "    \"GLOVE100_pca\":sentence_feature_GLOVE100,\n",
        "    \"BERT_pca_concat\":sentence_feature_normal_new,\n",
        "    \"tweetBERT_pca_concat\":sentence_feature_tweet_new,\n",
        "    \"GLOVE_pca_concat\":sentence_feature_GLOVE_new,\n",
        "    \"GLOVE50_pca_concat\":sentence_feature_GLOVE25_new,\n",
        "    \"GLOVE25_pca_concat\":sentence_feature_GLOVE50_new,\n",
        "    \"GLOVE100_pca_concat\":sentence_feature_GLOVE100_new,\n",
        "}"
      ],
      "metadata": {
        "id": "X34iBzQ-903X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJKSPedcge3"
      },
      "source": [
        "number_of_run = 5\n",
        "def AL_loop(rep,model,AL_stg):\n",
        "  \n",
        "  sentence_feature=reps_dict[rep]\n",
        "  data_test = sentence_feature[train_start:train_end+1]\n",
        "  strat = uncertainty_sampling\n",
        "  \n",
        "  if AL_stg==\"lc\": stg=False\n",
        "\n",
        "  if AL_stg==\"Random\": stg=True\n",
        "\n",
        "  if AL_stg==\"batch_lc\":\n",
        "    stg=False\n",
        "    strat = uncertainty_batch_sampling\n",
        "\n",
        "  if AL_stg==\"qbc\"or AL_stg=='boost' or AL_stg=='bag':\n",
        "    stg=False\n",
        "    print(AL_stg,'   ',rep,'    ',model)\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_commite(50,data_test, test_labels,number_of_run,model,strat,20,stg,AL_stg)\n",
        "  \n",
        "  if model==\"mlp\":\n",
        "    if rep!= \"GLOVE_pca_concat\":\n",
        "      print(model)\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy(50, data_test, test_labels,number_of_run,create_keras_model_berts,strat,20,stg)\n",
        "    else:\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy(50, data_test, test_labels,number_of_run,create_keras_model_GLOVE,strat,20,stg)  \n",
        "  elif AL_stg==\"epsilon_in_batch\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_epsilon_greedy(50,data_test, test_labels,number_of_run,model,strat,20,False)\n",
        "  elif AL_stg==\"epsilon_in_batch_rand\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_epsilon_greedy(50,data_test, test_labels,number_of_run,model,strat,20,True)\n",
        "  elif AL_stg==\"cross\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_cross(50,data_test, test_labels,number_of_run,model,strat,20,False)\n",
        "  elif AL_stg!=\"qbc\":\n",
        "    acc,f1,pref_random,pref_hist_majority,N_QUERIES = run_multy_sklearn(50,data_test, test_labels,number_of_run,model,strat,20,stg)\n",
        "\n",
        "  return acc,f1,pref_random,pref_hist_majority,N_QUERIES \n",
        "  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnwh_r6Wk4C"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# counter = 0\n",
        "# reps = ['GLOVE']\n",
        "# models = ['LR']\n",
        "# stratefies = ['lc'] \n",
        "\n",
        "# for rep in reps:\n",
        "#   for model in models:\n",
        "#     for AL_stg in stratefies:\n",
        "#       counter = counter+1\n",
        "#       acc,f1,pref_random,pref_hist_majority,N_QUERIES = AL_loop(rep,model,AL_stg)\n",
        " "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final run with different AL settings with Automated run setting set in previous section"
      ],
      "metadata": {
        "id": "uEAnmeRCu8Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "counter = 0\n",
        "reps = ['tweetBERT_pca_concat']\n",
        "models = ['mlp']\n",
        "stratefies = ['lc'] \n",
        "\n",
        "for rep in reps:\n",
        "  for model in models:\n",
        "    for AL_stg in stratefies:\n",
        "      counter = counter+1\n",
        "      acc,f1,pref_random,pref_hist_majority,N_QUERIES = AL_loop(rep,model,AL_stg)"
      ],
      "metadata": {
        "id": "OuyZ0HMm6QM5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "outputId": "e69f3bd2-eb14-4c6a-f177-5da604843845"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlp\n",
            "5 20\n",
            "x pool length (20, 64)\n",
            "y pool length (20, 2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-05bf5704fce4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mAL_stg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstratefies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_random\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_hist_majority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_QUERIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAL_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAL_stg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-371560eb0584>\u001b[0m in \u001b[0;36mAL_loop\u001b[0;34m(rep, model, AL_stg)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0;34m\"GLOVE_pca_concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_random\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_hist_majority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_QUERIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_keras_model_berts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_random\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpref_hist_majority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_QUERIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_multy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_keras_model_GLOVE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-5e49c559c93a>\u001b[0m in \u001b[0;36mrun_multy\u001b[0;34m(BATCH_SIZE, data_test, test_labels, num_of_run, model, strategy, train_size, is_random)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x pool length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y pool length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     learner = ActiveLearner(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mquery_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreset_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, query_strategy, X_training, y_training, bootstrap_init, on_transformed, **fit_kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m                  \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                  ) -> None:\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(estimator, query_strategy,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          X_training, y_training, bootstrap_init, on_transformed, **fit_kwargs)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/modAL/models/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, query_strategy, X_training, y_training, bootstrap_init, on_transformed, force_all_finite, **fit_kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'force_all_finite must be a bool'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/modAL/models/base.py\u001b[0m in \u001b[0;36m_fit_to_known\u001b[0;34m(self, bootstrap, **fit_kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mn_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 768), found shape=(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnVxfd3syJBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3b775c-00e3-46d2-9ffc-77e92b480436"
      },
      "source": [
        "acc_25perc_avg=acc[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "f1_25perc_avg=f1[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "\n",
        "# print(acc25_avg[-1])\n",
        "print(f1_25perc_avg[-1])  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7591833341246902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embedding\n",
        "Word embedding generation in case we don't want to used the pretrained saved models that was trained previously and saved on Github.\n",
        "The save representations on Github were made by code below."
      ],
      "metadata": {
        "id": "T_5DIrR4sEV-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZySdeJ5Icv-"
      },
      "source": [
        "### selecting test train eval set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jCWJyUcJthA"
      },
      "source": [
        "#### 0's topic test and rest train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWGCON7lwK_"
      },
      "source": [
        "data_cp =data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJO8UF-pk-Eu"
      },
      "source": [
        "topic_num = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCOpzX96IsrG"
      },
      "source": [
        "test_df = data[data['topic']==topic_num]\n",
        "train_df = data[data['topic']!=topic_num]\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqvHai1elpta",
        "outputId": "b854e46c-8277-4eda-b0b8-a9e34168dba7"
      },
      "source": [
        "data2=data.reset_index()\n",
        "start_test=data2[data2['topic']==topic_num].iloc[0]\n",
        "# end_test=data2[data2['topic']==0].iloc[-1]\n",
        "# start_train =data2[data2['topic']==1].iloc[0]\n",
        "# end_train = start_test=data2[data2['topic']==8].iloc[-1]\n",
        "def pd_iter_func(df,topic):\n",
        "    for row in df.itertuples():\n",
        "        # Define your criteria here\n",
        "        if row.topic ==topic:\n",
        "            return row\n",
        "start_test=pd_iter_func(data2,1).Index\n",
        "end_test = pd_iter_func(data2,2).Index-1\n",
        "train_start = pd_iter_func(data2,topic_num).Index\n",
        "train_end = len(data2)\n",
        "print(start_test,',',end_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2079 , 2092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcvb0IhoJ07V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83609b5-2982-4618-e409-6c88dce67ac9"
      },
      "source": [
        "train_sentences = train_df.text.values\n",
        "test_sentences = test_df.text.values\n",
        "train_labels = train_df.tag.values\n",
        "test_labels = test_df.tag.values\n",
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5MU4IIbsIC"
      },
      "source": [
        "#####over ride just 0 test and train for now\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVzNdJ46brdd"
      },
      "source": [
        "test_labels = test_df.tag.values\n",
        "train_start=0\n",
        "train_end=2078"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-esnaFdhBBS"
      },
      "source": [
        "### Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfWqiX7gYKI"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBU_Qv1muGQW"
      },
      "source": [
        "sentence_feature=np.load('/content/sentiment_new_approach/vectorization/normal_bert.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBnCn3fRo4JS"
      },
      "source": [
        "sentence_feature=np.load('/content/sentiment_new_approach/vectorization/tweet_bert.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXO_4GCgbjH7",
        "outputId": "15637dca-f3b2-4ace-a0a8-8614ec39da51"
      },
      "source": [
        "sentence_feature.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSfeIiaoeFJ"
      },
      "source": [
        "!pip install emoji\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oQ61gE0pnZL",
        "outputId": "76a5bd98-59b3-47ff-8876-45eb5e2542b0"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer \n",
        "# Load BERT TWEET tokenizer and model\n",
        "bert_tweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "tokenizer_tweet = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\",normalization=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1z0rI5FNVL"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "def tokenizer_func(tokenizer_kind,sentences,labels):\n",
        "  '''\n",
        "  inputs:\n",
        "    tokenizer_kind: is the the tokenizer of choice (normal bert, tweet bert)  \n",
        "    sentences: train , dev, test\n",
        "  outputs:\n",
        "  torchs of \n",
        "    ids\n",
        "    attention_mask\n",
        "    labels\n",
        "  '''\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer_kind.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 128,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          truncation=True,\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  return input_ids, attention_masks ,labels\n",
        "  # Print sentence 0, now as a list of IDs.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PO4WiaOFU01",
        "outputId": "d167a5a1-a2df-453b-a081-c962a831f994"
      },
      "source": [
        "sentences = data.text.values\n",
        "train_labels = data.tag.values\n",
        "input_ids,attention_masks,labels=tokenizer_func(tokenizer_tweet,sentences,train_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYB5FSknIx_u"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset\n",
        "batch_size=128\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSSKkuwzSJI4"
      },
      "source": [
        "bert_tweet.cuda()\n",
        "bert_tweet.eval()\n",
        "# Tracking variables \n",
        "sentence_feature=[]\n",
        "t1 = time.time()\n",
        "for batch in prediction_dataloader:\n",
        "  t0 = time.time()  \n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = bert_tweet(b_input_ids, attention_mask=b_input_mask)\n",
        "      \n",
        "  sentence_features_slice = outputs[0][:,0,:].cpu().numpy()  \n",
        "  # Store predictions and true labels\n",
        "  sentence_feature.append(sentence_features_slice)\n",
        "  elapsed = format_time(time.time() - t0)\n",
        "  print(\"time elapse:\",elapsed)\n",
        "print(\"full time\",format_time(time.time()-t1))\n",
        "sentence_feature = np.concatenate(sentence_feature, axis=0)\n",
        "print(sentence_feature.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZCCzuZFGqow"
      },
      "source": [
        "\n",
        "with open('tweet_bert.npy', 'wb') as f:\n",
        "    np.save(f, sentence_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsMJxBOXffm"
      },
      "source": [
        "#### Glove word embeding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3pjS7AaCiO_"
      },
      "source": [
        "##### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VJe6hrBCrC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c03b7936-8b86-435c-a264-1c113a36d7fe"
      },
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Change \"@name\" to \"Username\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    - change urls to \"Link\"\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Change \"@name\" to \"Username\n",
        "    s = re.sub(r'(@.*?)[\\s]', 'username', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    # change urls to \"Link\"\n",
        "    s = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",'link',s)\n",
        "    \n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jknz7wXACuzy"
      },
      "source": [
        "import numpy as np\n",
        "sentences = np.array([text_preprocessing(text) for text in data.text.values  ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsqrqPZpT9bp"
      },
      "source": [
        "#####Glove\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hylGOHjyL5Ic",
        "outputId": "e1caa90d-abdd-461c-c379-f60a82525dec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYotFrQnaFr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aabd7093-7d80-423c-be32-3378c11f3229"
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/glove.twitter.27B.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv59vXazjpqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6868a69b-bdef-4f5b-b2ab-7cc10a6b8a62"
      },
      "source": [
        "def loadGloveModel(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(File,'r')\n",
        "    gloveModel = {}\n",
        "    for line in f:\n",
        "        splitLines = line.split()\n",
        "        word = splitLines[0]\n",
        "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "        gloveModel[word] = wordEmbedding\n",
        "    print(len(gloveModel),\" words loaded!\")\n",
        "    return gloveModel\n",
        "glove = loadGloveModel('glove.twitter.27B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "1193514  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UePgEF3o8zY"
      },
      "source": [
        "\n",
        "data_train = np.zeros(shape=(len(sentences),50),dtype=np.float)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  tweet = sentences[i]\n",
        "  tweet = tweet.split(' ')\n",
        "  glove_word_count = 1\n",
        "  for word in tweet:\n",
        "    if word.lower() in glove:\n",
        "      glove_word_count +=1\n",
        "      data_train[i,:]+= glove[word]\n",
        "  data_train[i,:]=data_train[i,:]/(glove_word_count)\n",
        "features=data_train\n",
        "#representation Glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwDjsrB3lBRA"
      },
      "source": [
        "sentence_feature_GLOVE=features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p54Zd_3dvLRY",
        "outputId": "e1e64489-37dd-4c02-be97-441be604da84"
      },
      "source": [
        "sentence_feature_GLOVE.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBghjd46vsCu"
      },
      "source": [
        "save_reesult(sentence_feature_GLOVE,'GLOVE50.np')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}